{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import glob\n",
    "import h5py\n",
    "import cv2\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Input, Flatten, Lambda, Reshape, Cropping2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import scipy.stats as stats\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.distributed import Client\n",
    "from dask_image.imread import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ec391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the maximum image pixels limit\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# batch = 200\n",
    "batch = 2\n",
    "\n",
    "train_dir = 'train_folder'\n",
    "test_dir = 'test_folder'\n",
    "\n",
    "train_samples = len(glob.glob(os.path.join(train_dir, '**', '*.jpg'), recursive=True))\n",
    "test_samples = len(glob.glob(os.path.join(test_dir, '**', '*.jpg'), recursive=True))\n",
    "\n",
    "print(f\"Training samples: {train_samples}\")\n",
    "print(f\"Testing samples: {test_samples}\")\n",
    "\n",
    "# img_height, img_width = 15216, 21397 # Resize to smaller dimensions\n",
    "# img_height, img_width = 512, 512 # Resize to smaller dimensions\n",
    "# img_height, img_width = 32, 64 # Resize to smaller dimensions\n",
    "# img_height, img_width = 3044, 4280 # Resize to smaller dimensions\n",
    "img_height, img_width = 1522, 2140 # Resize to smaller dimensions\n",
    "\n",
    "\n",
    "\n",
    "num_channels = 3 # RGB\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training set in batches\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch,\n",
    "    class_mode=None,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "# Load test set in batches\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch,\n",
    "    class_mode=None,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "# Example of loading a batch\n",
    "x_train_small = next(train_generator)\n",
    "x_test_small = next(test_generator)\n",
    "\n",
    "print(\"Train batch shape:\", x_train_small.shape)\n",
    "print(\"Test batch shape:\", x_test_small.shape)\n",
    "\n",
    "img_shape = (img_height, img_width, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be52777",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_dir = 'anomaly_folder'\n",
    "\n",
    "anomaly_samples = len(glob.glob(os.path.join(anomaly_dir, '**', '*.jpg'), recursive=True))\n",
    "print(f\"Anomaly samples: {anomaly_samples}\")\n",
    "\n",
    "anomaly_generator = datagen.flow_from_directory(\n",
    "    anomaly_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    # batch_size=99999,\n",
    "    batch_size=batch,\n",
    "    class_mode=None,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "anomaly_data = next(anomaly_generator)\n",
    "anomaly_test_data = anomaly_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069379f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x_train_small))\n",
    "print(type(anomaly_data))\n",
    "print(len(x_train_small))\n",
    "print(len(x_test_small))\n",
    "print(len(anomaly_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73796ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train_small shape:\", x_train_small.shape)\n",
    "print(\"train_samples:\", train_samples)\n",
    "\n",
    "n = []\n",
    "a = 0\n",
    "for j in range(0, 10):\n",
    "    n.append(random.randint(0, len(x_train_small) - 1))  # Use -1 to avoid index out of range\n",
    "print(n)\n",
    "\n",
    "print('\\nFew of the training data samples are:')\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in n:\n",
    "    a = a + 1\n",
    "    ax = plt.subplot(2, 10, a)\n",
    "    plt.imshow(x_train_small[i])  # No reshape needed for RGB images\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "b = 0\n",
    "for j in range(0, 10):\n",
    "    f.append(random.randint(0, len(anomaly_data)-1))\n",
    "print(f)\n",
    "\n",
    "print('\\nFew of the Anomaly data samples are:')\n",
    "plt.figure(figsize=(20, 4))\n",
    "             \n",
    "for i in f:\n",
    "    b = b + 1\n",
    "    ax = plt.subplot(2, 10, b)\n",
    "    plt.imshow(anomaly_data[i])  # No reshape needed for RGB images\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape = img_shape)\n",
    "\n",
    "x = keras.layers.Conv2D(10, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = keras.layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# x = keras.layers.Conv2D(10, (3, 3), activation='relu', padding='same')(encoded)\n",
    "# x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "# x = keras.layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "# x = keras.layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "# x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "# decoded = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "x = keras.layers.Conv2D(10, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x)\n",
    "x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = keras.layers.UpSampling2D((2, 2))(x)\n",
    "# decoded = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "x = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "decoded = Cropping2D(((0,6), (0,4)))(x)  # Trim 6 rows and 4 columns\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Evaluation model where output is the loss\n",
    "loss_layer = Lambda(lambda x: K.mean(K.square(x[0] - x[1])), name='loss_layer', output_shape=lambda s: s[0])\n",
    "# Define the model\n",
    "model_evalloss = Model(inputs=[input_img, input_img], outputs=loss_layer([input_img, decoded]))\n",
    "# model_evalloss.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model_evalloss.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb98b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# x_train_small = x_train_small.astype('float16')/255.0\n",
    "# x_test_small = x_test_small.astype('float16')/255.0\n",
    "\n",
    "# # Example: Resize each image in the dataset to 128x128\n",
    "# x_train_small_resized = np.array([np.array(Image.open(img).resize((128, 128))) for img in x_train_small])\n",
    "# x_test_small_resized = np.array([np.array(Image.open(img).resize((128, 128))) for img in x_test_small])\n",
    "\n",
    "\n",
    "# print(f\"Training data size (GB): {x_train_small.nbytes / (1024**3):.2f} GB\")\n",
    "# print(\"Shape:\", x_train_small.shape)\n",
    "\n",
    "# print(f\"Testing data size (GB): {x_test_small.nbytes / (1024**3):.2f} GB\")\n",
    "# print(\"Shape:\", x_test_small.shape)\n",
    "\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# gpu_devices = tf.config.list_physical_devices('GPU')  # Non-experimental method\n",
    "# for device in gpu_devices:\n",
    "#     print(tf.config.experimental.get_memory_info(\"GPU:0\"))  # Use \"GPU:0\" directly\n",
    "\n",
    "\n",
    "def data_generator(x_data, batch_size):\n",
    "    while True:  # For infinite training\n",
    "        for i in range(0, len(x_data), batch_size):\n",
    "            x_batch = x_data[i:i+batch_size]\n",
    "            yield x_batch, x_batch  # for autoencoder: input = target\n",
    "\n",
    "# batch = 1  # or 2, depending on memory\n",
    "train_gen = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(x_train_small, batch),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 1522, 2140, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1522, 2140, 3), dtype=tf.float32),\n",
    "    )\n",
    ")\n",
    "\n",
    "val_gen = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(x_test_small, batch),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 1522, 2140, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 1522, 2140, 3), dtype=tf.float32),\n",
    "    )\n",
    ")\n",
    "\n",
    "a = autoencoder.fit(\n",
    "    train_gen,\n",
    "    # epochs=25,\n",
    "    epochs=20000,\n",
    "    steps_per_epoch=len(x_train_small) // batch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(x_test_small) // batch,\n",
    "    # callbacks=[GPUMemoryCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = autoencoder.evaluate(x_test_small, x_test_small, verbose=0)\n",
    "print (\"Test MSE loss:\", results)\n",
    "\n",
    "results_anom = autoencoder.evaluate(anomaly_data, anomaly_data, verbose=0)\n",
    "print (\"Anomaly MSE loss:\", results_anom)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw a test image\n",
    "im_test = autoencoder.predict(x_test_small[:1])\n",
    "plt.imshow(im_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dcebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw an anomaly image\n",
    "im = autoencoder.predict(anomaly_data[:1])\n",
    "plt.imshow(im[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test_small)\n",
    "decoded_imgs_anom = autoencoder.predict(anomaly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "loss = a.history['loss']\n",
    "val_loss = a.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, '-o', label='Training loss')\n",
    "plt.plot(epochs, val_loss, '-o', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d09bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "print(\"The orignal images are:\")\n",
    "for i in range(0, min(n, len(x_test_small))):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_small[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe reconstructed images are:\")\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(0, min(n, len(decoded_imgs))):\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
